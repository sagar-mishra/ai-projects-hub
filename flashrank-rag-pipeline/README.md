# ğŸ” FlashRank RAG: Document Search + QA with LangChain, FAISS & FlashRank

A minimal, production-ready RAG (Retrieval-Augmented Generation) app that supports both:

- ğŸ“„ Document Search with Reranking (FlashRank)
- ğŸ’¬ LLM-based Q&A from reranked document context
---

## ğŸ” What is Reranking and Why It Matters?

In traditional RAG pipelines, the retriever (e.g., FAISS) fetches documents based purely on vector similarity â€” which may not always reflect the **most relevant context** for answering the question.

Reranking solves this by:

1. ğŸ” Fetching **top-k** documents via semantic search (FAISS)
2. âš¡ Passing them through a **reranker model** (like FlashRank)
3. ğŸ“Š Sorting them based on how well they answer the query â€” not just similarity

This ensures your LLM gets the **most question-relevant chunks**, not just the most similar ones.

### ğŸ§  FlashRank in This Project

This app uses **LangChain's `FlashrankRerank`** via `ContextualCompressionRetriever` to perform fast and accurate reranking before the answer is generated.
--

## ğŸš€ Features

| Feature                        | Description                                                                 |
|--------------------------------|-----------------------------------------------------------------------------|
| âœ… Search Mode                 | Displays reranked documents only                                           |
| âœ… Chat Mode                   | Uses LLM to answer questions from top-ranked docs                         |
| âœ… FAISS Vector Store          | Efficient semantic indexing of your documents                             |
| âš¡ FlashRank Reranker          | Improves answer/document relevance using reranking                        |
| ğŸ”„ Dynamic Index Rebuilding    | Rebuild FAISS index from `sample.txt` anytime                             |
| ğŸ› ï¸ Fully Local Setup           | Works with Ollama models (e.g. `mistral`, `llama3`)                        |

---

## ğŸ—‚ï¸ Project Structure

flashrank-rag-pipeline/ <br>
â”œâ”€â”€ app.py # Streamlit UI <br>
â”œâ”€â”€ indexer.py # Builds & clears FAISS index <br>
â”œâ”€â”€ rag_chain.py # RAG chain wrapper <br>
â”œâ”€â”€ requirements.txt # Python dependencie <br>
â”œâ”€â”€ data/ <br>
â”‚ â””â”€â”€ sample.txt # Your input document <br>
â””â”€â”€ retriever/ <br>
â”‚ â””â”€â”€ retriever.txt # FAISS retriever <br> 
â”‚ â””â”€â”€ contextual_reranker.py # FlashRank + compression retriever <br>


---

## ğŸ§  Usage

<b> 1. ğŸ“ Add Your Data </b> <br>
Replace the contents of: data/sample.txt <br>
with your own .txt data or parsed output (e.g., from PDFs).
<br>

<b> 2. ğŸš€ Run the App </b> <br>
streamlit run app.py 
<br>

<b> 3. ğŸ“Œ Modes in UI </b> <br>
<ul>
    <li>Search Documents â†’ See reranked source documents</li>
    <li>Chat with RAG â†’ Ask questions and get answers from LLM + top docs</li>
</ul>

<b> 4. ğŸ”„ Rebuild the Index </b> <br>
If you've updated sample.txt, click: ğŸ”„ Rebuild Index Anyway <br>
This deletes the old FAISS index and builds a fresh one.



